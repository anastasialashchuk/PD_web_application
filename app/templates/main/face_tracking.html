<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Tracking with MediaPipe</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f7fa;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 25px;
        }
        .video-container {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto 20px;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        #videoElement {
            width: 100%;
            height: 100%;
            background-color: #000;
            display: block;
        }
        #processedCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 25px;
            flex-wrap: wrap;
        }
        button {
            padding: 12px 25px;
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.3s;
            min-width: 150px;
        }
        button:hover {
            background-color: #2980b9;
            transform: translateY(-2px);
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
            transform: none;
        }
        #startBtn {
            background-color: #2ecc71;
        }
        #startBtn:hover {
            background-color: #27ae60;
        }
        #stopBtn {
            background-color: #e74c3c;
        }
        #stopBtn:hover {
            background-color: #c0392b;
        }
        .settings {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 25px;
        }
        .settings h2 {
            margin-top: 0;
            color: #2c3e50;
            border-bottom: 1px solid #bdc3c7;
            padding-bottom: 10px;
        }
        .setting-group {
            margin-bottom: 15px;
        }
        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #34495e;
        }
        input[type="range"] {
            width: 100%;
            height: 8px;
            border-radius: 4px;
            background: #bdc3c7;
            outline: none;
        }
        input[type="number"] {
            width: 100%;
            padding: 8px;
            border: 1px solid #bdc3c7;
            border-radius: 4px;
            font-size: 16px;
        }
        .status {
            padding: 15px;
            background-color: #d5f5e3;
            border-radius: 8px;
            margin-bottom: 25px;
            text-align: center;
            font-weight: 600;
            color: #27ae60;
        }
        .expressions {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 25px;
            flex-wrap: wrap;
        }
        .expression {
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 8px;
            text-align: center;
            min-width: 120px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            transition: all 0.3s;
        }
        .expression.active {
            background-color: #d4edda;
            box-shadow: 0 4px 8px rgba(46, 204, 113, 0.2);
            transform: translateY(-5px);
        }
        .expression-icon {
            font-size: 24px;
            margin-bottom: 5px;
        }
        .recordings {
            margin-top: 30px;
        }
        .recordings h2 {
            color: #2c3e50;
            border-bottom: 1px solid #bdc3c7;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        .recording-item {
            padding: 15px;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            margin-bottom: 15px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: all 0.3s;
        }
        .recording-item:hover {
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            transform: translateY(-2px);
        }
        .recording-info {
            flex-grow: 1;
        }
        .recording-name {
            font-weight: 600;
            margin-bottom: 5px;
        }
        .recording-meta {
            font-size: 14px;
            color: #7f8c8d;
        }
        .recording-actions a {
            margin-left: 15px;
            color: #3498db;
            text-decoration: none;
            padding: 8px 12px;
            border-radius: 4px;
            transition: all 0.3s;
        }
        .recording-actions a:hover {
            background-color: #ebf5fb;
            text-decoration: underline;
        }
        .value-display {
            display: inline-block;
            margin-left: 10px;
            font-weight: normal;
            color: #7f8c8d;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Face Tracking with MediaPipe</h1>

        <div class="settings">
            <h2>Detection Settings</h2>
            <div class="setting-group">
                <label for="confidence">Confidence Threshold: <span id="confidenceValue" class="value-display">0.5</span></label>
                <input type="range" id="confidence" min="0.1" max="1" step="0.1" value="0.5">
            </div>

            <div class="setting-group">
                <label for="delay">Auto-Record Delay (seconds):</label>
                <input type="number" id="delay" min="0.5" max="10" step="0.5" value="2.0">
            </div>
        </div>

        <div class="video-container">
            <video id="videoElement" autoplay playsinline></video>
            <canvas id="processedCanvas"></canvas>
        </div>

        <div class="status" id="status">
            Initializing camera...
        </div>

        <div class="controls">
            <button id="startBtn">Start Recording</button>
            <button id="stopBtn" disabled>Stop Recording</button>
            <button id="saveBtn" disabled>Save Recording</button>
        </div>

        <div class="recordings">
            <h2>Saved Recordings</h2>
            <div id="recordingsList">
                <p>No recordings yet. Start tracking to see your recordings here.</p>
            </div>
        </div>
    </div>

    <script>
        // DOM elements
        const videoElement = document.getElementById('videoElement');
        const processedCanvas = document.getElementById('processedCanvas');
        const ctx = processedCanvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const saveBtn = document.getElementById('saveBtn');
        const statusDiv = document.getElementById('status');
        const confidenceInput = document.getElementById('confidence');
        const delayInput = document.getElementById('delay');
        const recordingsList = document.getElementById('recordingsList');
        const confidenceValue = document.getElementById('confidenceValue');

        // Expression elements
        const expressionElements = {
            'smile': document.getElementById('smile'),
            'eyebrows': document.getElementById('eyebrows'),
            'mouth': document.getElementById('mouth'),
            'eyes': document.getElementById('eyes')
        };

        // Variables
        let isProcessing = false;
        let isRecording = false;
        let frameCount = 0;
        let stream = null;

        // Initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 640 },
                        height: { ideal: 480 },
                        facingMode: 'user'
                    },
                    audio: false
                });
                videoElement.srcObject = stream;

                // Set canvas dimensions to match video
                videoElement.onloadedmetadata = () => {
                    processedCanvas.width = videoElement.videoWidth;
                    processedCanvas.height = videoElement.videoHeight;
                };

                statusDiv.textContent = "Camera ready. Face the camera to start tracking.";

                // Start processing frames
                processFrame();
            } catch (err) {
                console.error("Error accessing camera:", err);
                statusDiv.textContent = "Error accessing camera: " + err.message;
                statusDiv.style.backgroundColor = "#fadbd8";
                statusDiv.style.color = "#c0392b";
            }
        }

        // Process each video frame
        async function processFrame() {
            if (videoElement.readyState !== videoElement.HAVE_ENOUGH_DATA || isProcessing) {
                requestAnimationFrame(processFrame);
                return;
            }

            isProcessing = true;

            // Draw video frame to canvas
            ctx.drawImage(videoElement, 0, 0, processedCanvas.width, processedCanvas.height);

            // Get image data from canvas
            const imageData = processedCanvas.toDataURL('image/jpeg');

            try {
                const response = await fetch('/process_frame', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-Confidence': confidenceInput.value,
                        'X-Delay': delayInput.value
                    },
                    body: JSON.stringify({ image: imageData })
                });

                const data = await response.json();

                if (data.status === 'success') {
                    // Update status
                    frameCount = data.frame_count || 0;

                    if (data.is_recording) {
                        statusDiv.textContent = `Recording - ${frameCount} frames captured`;
                        statusDiv.style.backgroundColor = "#fadbd8";
                        statusDiv.style.color = "#c0392b";
                        isRecording = true;
                        startBtn.disabled = true;
                        stopBtn.disabled = false;
                        saveBtn.disabled = false;
                    } else {
                        statusDiv.textContent = `Ready - ${frameCount} frames captured`;
                        statusDiv.style.backgroundColor = "#d5f5e3";
                        statusDiv.style.color = "#27ae60";
                        isRecording = false;
                        startBtn.disabled = false;
                        stopBtn.disabled = true;
                    }

                    // Update expression indicators
                    if (data.face_data && data.face_data.expressions) {
                        const expressions = data.face_data.expressions;

                        for (const [key, element] of Object.entries(expressionElements)) {
                            if (expressions[key]) {
                                element.classList.add('active');
                            } else {
                                element.classList.remove('active');
                            }
                        }
                    }

                    // Draw processed image if available
                    if (data.processed_image) {
                        const img = new Image();
                        img.onload = function() {
                            ctx.drawImage(img, 0, 0, processedCanvas.width, processedCanvas.height);
                        };
                        img.src = data.processed_image;
                    }
                } else {
                    console.error("Error processing frame:", data.message);
                }
            } catch (err) {
                console.error("Error processing frame:", err);
                statusDiv.textContent = "Error processing frame: " + err.message;
                statusDiv.style.backgroundColor = "#fadbd8";
                statusDiv.style.color = "#c0392b";
            }

            isProcessing = false;
            requestAnimationFrame(processFrame);
        }

        // Start recording
        startBtn.addEventListener('click', async () => {
            try {
                const response = await fetch('/process_frame', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-Confidence': confidenceInput.value,
                        'X-Delay': delayInput.value
                    },
                    body: JSON.stringify({
                        image: processedCanvas.toDataURL('image/jpeg'),
                        command: 'start_recording'
                    })
                });

                const data = await response.json();

                if (data.status === 'success') {
                    isRecording = true;
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    saveBtn.disabled = false;
                    statusDiv.textContent = "Recording started...";
                    statusDiv.style.backgroundColor = "#fadbd8";
                    statusDiv.style.color = "#c0392b";
                }
            } catch (err) {
                console.error("Error starting recording:", err);
                statusDiv.textContent = "Error starting recording: " + err.message;
                statusDiv.style.backgroundColor = "#fadbd8";
                statusDiv.style.color = "#c0392b";
            }
        });

        // Stop and save recording
        stopBtn.addEventListener('click', async () => {
            try {
                const response = await fetch('/save_recording', {
                    method: 'POST'
                });

                const data = await response.json();

                if (data.status === 'success') {
                    isRecording = false;
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    saveBtn.disabled = true;
                    statusDiv.textContent = `Recording saved with ${data.frame_count} frames`;
                    statusDiv.style.backgroundColor = "#d5f5e3";
                    statusDiv.style.color = "#27ae60";

                    // Add to recordings list
                    addRecordingToList(data.video_path, data.json_path, data.frame_count);
                }
            } catch (err) {
                console.error("Error saving recording:", err);
                statusDiv.textContent = "Error saving recording: " + err.message;
                statusDiv.style.backgroundColor = "#fadbd8";
                statusDiv.style.color = "#c0392b";
            }
        });

        // Save button (same as stop)
        saveBtn.addEventListener('click', () => stopBtn.click());

        // Confidence slider update
        confidenceInput.addEventListener('input', () => {
            confidenceValue.textContent = confidenceInput.value;
        });

        // Add recording to the list
        function addRecordingToList(videoPath, jsonPath, frames) {
            const filename = videoPath.split('/').pop();
            const timestamp = filename.replace('recording_', '').replace('.mp4', '');
            const date = new Date(
                timestamp.substring(0, 4),
                timestamp.substring(4, 6) - 1,
                timestamp.substring(6, 8),
                timestamp.substring(9, 11),
                timestamp.substring(11, 13),
                timestamp.substring(13, 15)
            );

            const recordingItem = document.createElement('div');
            recordingItem.className = 'recording-item';

            recordingItem.innerHTML = `
                <div class="recording-info">
                    <div class="recording-name">${filename}</div>
                    <div class="recording-meta">
                        ${frames} frames â€¢ ${date.toLocaleString()}
                    </div>
                </div>
                <div class="recording-actions">
                    <a href="/recordings/${filename}" download title="Download Video">Download Video</a>
                    <a href="/recordings/${jsonPath.split('/').pop()}" download title="Download Data">Download Data</a>
                </div>
            `;

            if (recordingsList.firstChild && recordingsList.firstChild.tagName === 'P') {
                recordingsList.removeChild(recordingsList.firstChild);
            }

            recordingsList.insertBefore(recordingItem, recordingsList.firstChild);
        }

        // Load existing recordings on page load
        async function loadRecordings() {
            try {
                // In a real application, you would fetch this from your server
                // For now we'll just show the "no recordings" message
            } catch (err) {
                console.error("Error loading recordings:", err);
            }
        }

        // Initialize the app
        document.addEventListener('DOMContentLoaded', () => {
            initCamera();
            loadRecordings();

            // Update confidence display initially
            confidenceValue.textContent = confidenceInput.value;
        });

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>